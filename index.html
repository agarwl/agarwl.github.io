---
layout: layout
redirect_from: "/beta"
title: "Rishabh Agarwal"
---


<div class="row">
	<div class="seven columns">
		<p> I work on reinforcement learning and reaaoning in the LLama team at Meta, based out of Montreal. I am also an Adjunct Professor at McGill University. Previously, I was a staff research scientist in the <a href="https://deepmind.google/"> Google DeepMind Team </a>.  I finished my PhD at Mila under the guidance of Aaron Courville and Marc Bellemare.   
		Previously, I spent a year at Geoffrey Hinton's amazing team in Google Brain, Toronto. Earlier, I graduated in Computer Science and Engineering from IIT Bombay. </p>
<!--  		I also had a brief stint at Latent Logic (acquired by <a href="https://waymo.com/">Waymo</a>), a self-driving car startup in Oxford -->
		<p> My current research revolves around RL and LLMs, and my prior work has received 
		    an <a href="https://agarwl.github.io/rliable/">outstanding paper award</a> at NeurIPS.
		</p>

<!-- 		<center class="prof-summary"> <h1 class="page-heading"><a class="post-link " href="/about">Professional Summary</a> </h1></center> -->
	</div>

    <div class="five columns">
        <img src="images/rishabh_profile.jpg" id="profile_picture"> </img>
	</div>
</div>

<h3>Current PhD Students </h3>
<ul>
	<li> Morgane Moss (Co-supervised with Aaron Courville) </li>
</ul>

<h3> Past Mentees & Student Researchers </h3>
<ul>
	<li> Max Schwarzer (<a href="https://arxiv.org/abs/2305.19452">BBF</a>, Now o1 @ OpenAI) </li>
	<li> Yongchao Zhou (<a href="https://arxiv.org/abs/2310.08461">DistillSpec</a>, Now @ x.AI) </li>
	<li> Arian Hosseini (<a href="https://arxiv.org/abs/2402.06457">V-STaR</a>, PhD @ Mila) </li>
	<li> Jesse Farebrother (<a href="https://arxiv.org/abs/2403.03950">Stop Regressing</a>, PhD @ McGill) </li>
	<li> Lunjun Zhang (<a href="https://arxiv.org/abs/2408.15240">Generative RMs</a>, PhD @ UofT) </li>
	<li> Charline Le Lan (<a href="https://arxiv.org/abs/2203.00543">RL Generalization</a>, Now Gemini Flash @ GDM) </li>
	<li> Michael Noukhovitch (<a href="https://arxiv.org/abs/2410.18252"> Asynchronous RL for LLMs</a>, PhD @ Mila) </li>
	<li> Wenda Xu (<a href="https://arxiv.org/abs/2410.11325">Speculative KD </a>, PhD @ UCSB) </li>
	<li> Hritik Bansal (<a href="https://arxiv.org/abs/2408.16737">Compute-Optimal STaR / KD / W2S </a>, PhD @ UCLA) </li>
	<li> Josh P Zitovsky (<a href="https://arxiv.org/abs/2302.00141">Offline Model Selection</a>, Now @ Amazon)</li>
	<li> Amrith Setlur (<a href="https://arxiv.org/abs/2410.08146">Advantage for PRMs </a>, PhD @ UC Berkeley)</li>
	<li> Ghada Sokar (<a href="https://arxiv.org/abs/2302.12902">Dormant Neurons</a>, Now @ GDM) </li>	
	<li> Siddhant Agarwal (Undergrad Researcher, Now PhD @ UT Austin )</li>
</ul>

<h3 id='news'> News </h1>
<ul>
  <li> Tutorial on <a href="https://drive.google.com/file/d/1xMohjQcTmQuUd_OiZ3hB1r47WB1WM3Am/view"> Post-Training Distillation of LLMs </a> at Google. <a href="https://www.youtube.com/watch?v=O1AR4iL30mg"> [Podcast @ Youtube] </a>  </li> 
  <li> 7 papers accepted at ICLR 2025, including <a href="https://arxiv.org/abs/2408.15240"> Generative Verifiers </a>, <a href="https://arxiv.org/abs/2409.12917"> SCoRE </a>,  <a href="https://arxiv.org/abs/2410.11325"> Speculative KD</a>, <a href="https://arxiv.org/abs/2410.18252"> Async RLHF</a>, and <a href="https://arxiv.org/abs/2412.15287"> Inference-aware RL for LLMs </a>. </li> 
  <li> Panelist on the <a href="https://cmu-l3.github.io/neurips2024-inference-tutorial/"> Inference Time LLM Algorithms </a> Tutorial at NeurIPS 2024. </li>
  <li> Gave a guest lecture at McGill about <a href="https://drive.google.com/file/d/1komQ7s9kPPvDx_8AxTh9A6tlfJA0j6dR/view"> RL, Reasoning, and Verifiers. </a> </li>
  <li> <a href="https://arxiv.org/abs/2404.11018"> Many-Shot ICL </a> and  <a href="https://arxiv.org/abs/2407.04622"> Scalable Oversight </a> accepted at NeurIPS 2024 </li>	
<!--   <li> 4 papers, including an oral, accepted at ICML'23. </li>
  <li> 3 papers, including an oral, accepted at ICLR'23 (related to scaling TD methods) and one paper accepted at AISTATS'23. </li>
  <li> Co-organizing an in-person workshop on <a href="https://reincarnating-rl.github.io"> Reincarnating RL </a> at ICLR 2023 in Kigali, Rwanda. </li>
  <li> Talk on Reincarnating RL at the <a href="https://upml2022.github.io/"> UpML workshop </a> at ICML 2022.</li>
  <li> Co-organizing an in-person workshop on "Offline RL as a Launchpad" at NeurIPS 2022.</li>
  <li> One paper each accepted at AAAI'22, AISTATS'22, and ICLR'22. </li>
  <li> Co-organizing a workshop on "<a href="https://ml-eval.github.io"> Setting ML Evaluation Standards to Accelerate Progress </a> at ICLR 2022. </li>   	
  <li> <a href="https://blog.neurips.cc/2021/11/30/announcing-the-neurips-2021-award-recipients/?s=09">Outstanding paper award</a> at NeurIPS 2021 </li>
  <li> Two papers accepted at NeurIPS 2021: one <a href="https://agarwl.github.io/rliable/"> oral presentation </a> and one spotlight. </li>
  <li> Co-organizing the <a href="https://offline-rl-neurips.github.io/2021"> 2nd Offline RL workshop</a> at NeurIPS 2021.</li>
  <li> Two papers (including one spotlight presentation) accepted at ICLR 2021. </li> 
  <li> At NeurIPS 2020, I'll be giving a talk "Contrastive Behavioral Similarity Embeddings for Generalization in RL" at the <a href="https://nips.cc/Conferences/2020/Schedule?showEvent=16109">Biological and Artifical RL Workshop</a>. </li> 
  <li> Gave a talk about Offline RL at<a href="http://mlcollective.org/dlct"> ML Collective Reading Group </a>. </li>
  <li> Organizing a workshop on <a href="https://offline-rl-neurips.github.io"> Offline RL</a> at NeurIPS 2020.</li> 
  <li> Two papers accepted at ICML 2020. </li>
  <li> Gave a talk at Stanford about <a href="https://offline-rl.github.io">offline reinforcement learning</a>
  <li> At NeurIPS 2019, I <a href='https://slideslive.com/38922027/deep-reinforcement-learning-3?t=1728'>gave a talk </a> about our work on <a href='https://offline-rl.github.io'>offline RL</a> in the Deep RL Workshop.</li>
  <li> At ICML 2019, I <a href="https://youtu.be/_IXj6kXPdq8"> gave a talk </a> about our work on <a href="https://arxiv.org/abs/1902.07198"> Learning to Generalize from Sparse and Underspecified Rewards. </a> -->
</ul>
